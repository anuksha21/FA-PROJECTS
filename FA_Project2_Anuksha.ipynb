{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('CoronavirusNLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coviddata=spark.read.csv('Corona_NLP_train.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------+----------+--------------------+---------+\n",
      "|UserName|  ScreenName|            Location|   TweetAt|       OriginalTweet|Sentiment|\n",
      "+--------+------------+--------------------+----------+--------------------+---------+\n",
      "|    3799|       48751|              London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
      "|    3800|       48752|                  UK|16-03-2020|advice Talk to yo...| Positive|\n",
      "|    3801|       48753|           Vagabonds|16-03-2020|Coronavirus Austr...| Positive|\n",
      "|    3802|       48754|                null|16-03-2020|My food stock is ...|     null|\n",
      "|  PLEASE| don't panic| THERE WILL BE EN...|      null|                null|     null|\n",
      "+--------+------------+--------------------+----------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Coviddata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coviddata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68046, 6)\n"
     ]
    }
   ],
   "source": [
    "print((Coviddata.count(),len(Coviddata.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coviddata=Coviddata.withColumn('Tweet_length', length(Coviddata['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "|UserName|  ScreenName|            Location|   TweetAt|       OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "|    3799|       48751|              London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         111|\n",
      "|    3800|       48752|                  UK|16-03-2020|advice Talk to yo...| Positive|         237|\n",
      "|    3801|       48753|           Vagabonds|16-03-2020|Coronavirus Austr...| Positive|         131|\n",
      "|    3802|       48754|                null|16-03-2020|My food stock is ...|     null|          51|\n",
      "|  PLEASE| don't panic| THERE WILL BE EN...|      null|                null|     null|        null|\n",
      "+--------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Coviddata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=['Positive','Negative','Neutral','Extremely Positive','Extremely Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Coviddata.filter(Coviddata.Sentiment.isin(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         Sentiment|\n",
      "+------------------+\n",
      "|Extremely Negative|\n",
      "|           Neutral|\n",
      "|          Positive|\n",
      "|          Negative|\n",
      "|Extremely Positive|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Sentiment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('Sentiment').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|         Sentiment|count|\n",
      "+------------------+-----+\n",
      "|Extremely Negative| 3751|\n",
      "|           Neutral| 5224|\n",
      "|          Positive| 7718|\n",
      "|          Negative| 6857|\n",
      "|Extremely Positive| 4412|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('Sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+---------+------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------+----------+--------------------+----------+--------------------+---------+------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         111|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...| Positive|         237|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...| Positive|         131|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...| Positive|         249|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...| Positive|         184|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...| Positive|         280|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...| Negative|         267|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|  Neutral|         276|\n",
      "+--------+----------+--------------------+----------+--------------------+---------+------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27962, 7)\n"
     ]
    }
   ],
   "source": [
    "print((data.count(),len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|       0|         0|    6152|      0|            0|        0|           0|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan,when,count,col\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing using Tokenization, Stemming and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer,RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tokenizer=Tokenizer(inputCol=\"OriginalTweet\", outputCol=\"token_text\")\n",
    "stopremove=StopWordsRemover(inputCol=\"token_text\", outputCol=\"stop_tokens\")\n",
    "countvec=CountVectorizer(inputCol=\"stop_tokens\", outputCol=\"c_vec\")\n",
    "idf=IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "\n",
    "#Convert labels to numeric\n",
    "Labels_to_num=StringIndexer(inputCol=\"Sentiment\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedtext=VectorAssembler(inputCols=[\"tf_idf\",\"Tweet_length\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "NaiveB= NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "datapipeline= Pipeline(stages=(Labels_to_num, tokenizer, stopremove, countvec, idf, cleanedtext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data=datapipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=f_data.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|Tweet_length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|         111|  2.0|[@menyrbie, @phil...|[@menyrbie, @phil...|(78305,[14496,265...|(78305,[14496,265...|(78306,[14496,265...|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|         237|  0.0|[advice, talk, to...|[advice, talk, ne...|(78305,[13,14,133...|(78305,[13,14,133...|(78306,[13,14,133...|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|         131|  0.0|[coronavirus, aus...|[coronavirus, aus...|(78305,[8,14,37,7...|(78305,[8,14,37,7...|(78306,[8,14,37,7...|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|         249|  0.0|[as, news, of, th...|[news, regions, ...|(78305,[7,8,31,47...|(78305,[7,8,31,47...|(78306,[7,8,31,47...|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|         184|  0.0|[\"cashier, at, gr...|[\"cashier, grocer...|(78305,[3,6,18,60...|(78305,[3,6,18,60...|(78306,[3,6,18,60...|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|         280|  0.0|[due, to, covid-1...|[due, covid-19, r...|(78305,[1,6,8,13,...|(78305,[1,6,8,13,...|(78306,[1,6,8,13,...|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|         267|  1.0|[for, corona, pre...|[corona, preventi...|(78305,[11,13,14,...|(78305,[11,13,14,...|(78306,[11,13,14,...|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|         276|  2.0|[all, month, ther...|[month, crowding,...|(78305,[48,70,147...|(78305,[48,70,147...|(78306,[48,70,147...|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|         278|  3.0|[#horningsea, is,...|[#horningsea, car...|(78305,[13,14,23,...|(78305,[13,14,23,...|(78306,[13,14,23,...|\n",
      "|    3813|     48765|                null|16-03-2020|ADARA Releases CO...|          Positive|         185|  0.0|[adara, releases,...|[adara, releases,...|(78305,[8,10,23,5...|(78305,[8,10,23,5...|(78306,[8,10,23,5...|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|         184|  0.0|[for, those, who,...|[struggling,, ple...|(78305,[4,8,24,38...|(78305,[4,8,24,38...|(78306,[4,8,24,38...|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|         251|  4.0|[with, 100, , nat...|[100, , nations, ...|(78305,[1,4,9,11,...|(78305,[1,4,9,11,...|(78306,[1,4,9,11,...|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|         255|  1.0|[@10downingstreet...|[@10downingstreet...|(78305,[4,21,44,7...|(78305,[4,21,44,7...|(78306,[4,21,44,7...|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|         278|  3.0|[uk, #consumer, p...|[uk, #consumer, p...|(78305,[10,37,54,...|(78305,[10,37,54,...|(78306,[10,37,54,...|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|         202|  1.0|[in, preparation,...|[preparation, hig...|(78305,[4,8,24,33...|(78305,[4,8,24,33...|(78306,[4,8,24,33...|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|         279|  4.0|[this, morning, i...|[morning, tested,...|(78305,[1,7,11,36...|(78305,[1,7,11,36...|(78306,[1,7,11,36...|\n",
      "|    3829|     48781|                null|16-03-2020|There Is of in th...|          Negative|         114|  1.0|[there, is, of, i...|[country, , empty...|(78305,[1,4,7,34,...|(78305,[1,4,7,34,...|(78306,[1,4,7,34,...|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|         122|  2.0|[went, to, the, s...|[went, supermarke...|(78305,[5,47,48,6...|(78305,[5,47,48,6...|(78306,[5,47,48,6...|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|         225|  0.0|[worried, about, ...|[worried, impact,...|(78305,[8,12,23,2...|(78305,[8,12,23,2...|(78306,[8,12,23,2...|\n",
      "|    3837|     48789|                null|16-03-2020|my wife works ret...|          Negative|         288|  1.0|[my, wife, works,...|[wife, works, ret...|(78305,[6,28,33,9...|(78305,[6,28,33,9...|(78306,[6,28,33,9...|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=cleaned_data.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|(78306,[14496,265...|\n",
      "|  0.0|(78306,[13,14,133...|\n",
      "|  0.0|(78306,[8,14,37,7...|\n",
      "|  0.0|(78306,[7,8,31,47...|\n",
      "|  0.0|(78306,[3,6,18,60...|\n",
      "|  0.0|(78306,[1,6,8,13,...|\n",
      "|  1.0|(78306,[11,13,14,...|\n",
      "|  2.0|(78306,[48,70,147...|\n",
      "|  3.0|(78306,[13,14,23,...|\n",
      "|  0.0|(78306,[8,10,23,5...|\n",
      "|  0.0|(78306,[4,8,24,38...|\n",
      "|  4.0|(78306,[1,4,9,11,...|\n",
      "|  1.0|(78306,[4,21,44,7...|\n",
      "|  3.0|(78306,[10,37,54,...|\n",
      "|  1.0|(78306,[4,8,24,33...|\n",
      "|  4.0|(78306,[1,7,11,36...|\n",
      "|  1.0|(78306,[1,4,7,34,...|\n",
      "|  2.0|(78306,[5,47,48,6...|\n",
      "|  0.0|(78306,[8,12,23,2...|\n",
      "|  1.0|(78306,[6,28,33,9...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, testing)= cleaned_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=NaiveB.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test=predictor.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(78306,[0,1,2,12,...|[-1143.5999899435...|[0.96914164087953...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,17,...|[-2252.3386087643...|[2.52482603752474...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,23,...|[-1342.7138712802...|[0.99999821901192...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,29,...|[-1846.2153710491...|[1.38582176477374...|       1.0|\n",
      "|  0.0|(78306,[0,1,2,38,...|[-1837.1749904956...|[1.02531258613975...|       1.0|\n",
      "|  0.0|(78306,[0,1,2,40,...|[-1037.3850439223...|[2.83672560973375...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,4,6...|[-1425.6934259789...|[2.77145331652950...|       1.0|\n",
      "|  0.0|(78306,[0,1,3,4,1...|[-1378.6232334484...|[0.99997676755749...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,4,1...|[-1215.1431995339...|[3.94330683715480...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1123.1354784265...|[0.98716883354416...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,3...|[-1108.1720136805...|[3.40198510496386...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[-1938.9006018943...|[0.99996853594063...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[-548.58276839991...|[8.00023742183363...|       1.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-919.74384643599...|[1.36049006738309...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1475.6224006050...|[6.53467883373151...|       2.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-360.95874867190...|[9.04596599430670...|       1.0|\n",
      "|  0.0|(78306,[0,1,3,7,1...|[-1711.5981111547...|[2.38227771589996...|       1.0|\n",
      "|  0.0|(78306,[0,1,3,12,...|[-1582.0067322468...|[0.99999685942139...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,16,...|[-1434.8807967394...|[1.69555093382537...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,20,...|[-1462.7980824615...|[1.49221365482732...|       3.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluation= MulticlassClassificationEvaluator()\n",
    "acc=accuracy_evaluation.evaluate(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the model is :> 0.40452495881641615\n"
     ]
    }
   ],
   "source": [
    "print (\"The Accuracy of the model is :>\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
